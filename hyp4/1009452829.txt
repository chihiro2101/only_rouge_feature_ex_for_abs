normally , on modern systems , the target of overclocking is increasing the performance of a major chip or subsystem , such as the main processor or graphics controller , but other components , such as system memory ( ram ) or system buses ( generally on the motherboard ) , are commonly involved the trade-offs are an increase in power consumption ( heat ) , fan noise ( cooling ) , and shortened lifespan for the targeted components most components are designed with a margin of safety to deal with operating conditions outside of a manufacturer 's control ; examples are ambient temperature and fluctuations in operating voltage overclocking techniques in general aim to trade this safety margin by setting the device to run in the higher end of the margin , with the understanding that temperature and voltage must be more strictly monitored and controlled by the user examples are that operating temperature would need to be more strictly controlled with increased cooling , as the part will be less tolerant of increased temperatures at the higher speeds past this speed the device starts giving incorrect results , which can cause malfunctions and sporadic behavior in any system depending on it while in a pc context the usual result is a system crash , more subtle errors can go undetected , which over a long enough time can give unpleasant surprises such as data corruption ( incorrectly calculated results , or worse writing to storage incorrectly ) or the system failing only during certain specific tasks ( general usage such as internet browsing and word processing appear fine , but any application wanting advanced graphics crashes the system ) at some point there will be a limit imposed by the ability to supply the device with sufficient power , the user 's ability to cool the part , and the device 's own maximum voltage tolerance before it achieves destructive failure the speed gained by overclocking depends largely upon the applications and workloads being run on the system , and what components are being overclocked by the user ; benchmarks for different purposes are published conversely , the primary goal of underclocking is to reduce power consumption and the resultant heat generation of a device , with the trade-offs being lower clock speeds and reductions in performance reducing the cooling requirements needed to keep hardware at a given operational temperature has knock-on benefits such as lowering the number and speed of fans to allow quiet pc , and in mobile devices increase the length of battery life per charge some manufacturers underclock components of battery-powered equipment to improve battery life , or implement systems that detect when a device is operating under battery power and reduce clock frequency underclocking and undervolting would be attempted on a desktop system to have it operate silently ( such as for a home entertainment center ) while potentially offering higher performance than currently offered by low-voltage processor offerings this would use a '' standard-voltage '' part and attempt to run with lower voltages ( while attempting to keep the desktop speeds ) to meet an acceptable performance/noise target for the build however again like overclocking there is no guarantee of success , and the builder 's time researching given system/processor combinations and especially the time and tedium of performing many iterations of stability testing need to be considered however , the practice is embraced more by enthusiasts than professional users , as overclocking carries a risk of reduced reliability , accuracy and damage to data and equipment while overclocking can still be an option for increasing personal computing capacity , and thus workflow productivity for professional users , the importance of stability testing components thoroughly before employing them into a production environment can not be overstated a general trend in the computing industry is that new technologies tend to debut in the high-end market first , then later trickle down to the performance and mainstream market if the high-end part only differs by an increased clock speed , an enthusiast can attempt to overclock a mainstream part to simulate the high-end offering this can give insight on how over-the-horizon technologies will perform before they are officially available on the mainstream market , which can be especially helpful for other users considering if they should plan ahead to purchase or upgrade to the new feature when it is officially released some hobbyists enjoy building , tuning , and '' hot-rodding '' their systems in competitive benchmarking competitions , competing with other like-minded users for high scores in standardized computer benchmark suites another approach is overclocking older components to attempt to keep pace with increasing system requirements and extend the useful service life of the older part or at least delay a purchase of new hardware solely for performance reasons another rationale for overclocking older equipment is even if overclocking stresses equipment to the point of failure earlier , little is lost as it is already depreciated , and would have needed to be replaced in any case technically any component that uses a timer ( or clock ) to synchronize its internal operations can be overclocked most efforts for computer components however focus on specific components , such as , processors ( a.k.a computer processors generally are overclocked by manipulating the cpu multiplier if that option is available , but the processor and other components can also be overclocked by increasing the base speed of the bus clock some systems allow additional tuning of other clocks ( such as a clock rate ) that influence the bus clock speed that , again is multiplied by the processor to allow for finer adjustments of the final processor speed most oem systems do not expose to the user the adjustments needed to change processor clock speed or voltage in the bios of the oem 's motherboard , which precludes overclocking ( for warranty and support reasons ) components will generally show some sort of malfunctioning behavior or other indication of compromised stability that alerts the user that a given speed is not stable , but there is always a possibility that a component will permanently fail without warning , even if voltages are kept within some pre-determined safe values the end-point of a given overclock is determined by parameters such as available cpu multipliers , bus dividers , voltages ; the user 's ability to manage thermal loads , cooling techniques ; and several other factors of the individual devices themselves such as semiconductor clock and thermal tolerances , interaction with other components and the rest of the system first is to ensure that the component is supplied with adequate power at a voltage sufficient to operate at the new clock rate supplying the power with improper settings or applying excessive voltage can permanently damage a component in a professional production environment , overclocking is only likely to be used where the increase in speed justifies the cost of the expert support required , the possibly reduced reliability , the consequent effect on maintenance contracts and warranties , and the higher power consumption voltage increases power consumption and consequently heat generation significantly ( proportionally to the square of the voltage in a linear circuit , for example ) ; this requires more cooling to avoid damaging the hardware by overheating stock cooling systems are designed for the amount of power produced during non-overclocked use ; overclocked circuits can require more cooling , such as by powerful fans , larger heat sinks , heat pipes and water cooling submersion cooling , used by the cray-2 supercomputer , involves sinking a part of computer system directly into a chilled liquid that is thermally conductive but has low electrical conductivity however , this practice is discouraged due to its safety risks ; the solvents are flammable and volatile , and dry ice can cause frostbite ( through contact with exposed skin ) and suffocation ( due to the large volume of carbon dioxide generated when it sublimes ) a large-scale 2011 field study of hardware faults causing a system crash for consumer pcs and laptops showed a four to 20 times increase ( depending on cpu manufacturer ) in system crashes due to cpu failure for overclocked computers over an eight-month period to further complicate matters , in process technologies such as silicon on insulator ( soi ) , devices display hysteresis & mdash ; a circuit 's performance is affected by the events of the past , so without carefully targeted tests it is possible for a particular sequence of state changes to work at overclocked rates in one situation but not another even if the voltage and temperature are the same for instance : many motherboards with athlon 64 processors limit the clock rate of four units of ram to 333 mhz however , the memory performance is computed by dividing the processor clock rate ( which is a base number times a cpu multiplier , for instance 1.8 & nbsp ; ghz is most likely 9Ã—200 & nbsp ; mhz ) by a fixed integer such that , at a stock clock rate , the ram would run at a clock rate near 333 & nbsp ; mhz therefore , it could be wise to set this middle-stage prior to '' serious '' overclocking , specifically because of this fallback ability ; the card can drop down to this clock rate , reducing by a few ( or sometimes a few dozen , depending on the setting ) percent of its efficiency and cool down , without dropping out of 3d mode ( and afterwards return to the desired high performance clock and voltage settings ) 